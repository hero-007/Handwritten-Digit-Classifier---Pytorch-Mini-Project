{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten_Digits_Classifier.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9cKPNTGaNI7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W0z8UTFfXGAE",
        "colab_type": "code",
        "outputId": "03f03b9a-dfc6-4359-9022-5808f99b229d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install helper"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting helper\n",
            "  Downloading https://files.pythonhosted.org/packages/be/27/80bdb3e3bd9808db34ef38b332e984ba955a09d896231ef2ca62564cb6f9/helper-2.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from helper) (3.13)\n",
            "Installing collected packages: helper\n",
            "Successfully installed helper-2.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HbfzyHXLNcEE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision import datasets,transforms\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xBhWcbP2R8Ed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading mnist dataset from torchvision module\n",
        "\n",
        "# Defining a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),])\n",
        "\n",
        "# Download and Load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBlERJTzOlAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_train_nn(dataset):\n",
        "  # Creating a dense neural network with 2 hidden layers to classify handwritten digits\n",
        "  model = nn.Sequential(nn.Linear(784,128),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(128,64),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(64,10),\n",
        "                       nn.LogSoftmax(dim=1))\n",
        "  \n",
        "  # creterion variable contains the loss function \n",
        "  criterion = nn.NLLLoss()\n",
        "  # optimizer will update the weights based on the gradient calculated using backpropagation\n",
        "  optimizer = optim.SGD(model.parameters(),lr=0.003)\n",
        "  \n",
        "  epochs = 5\n",
        "  for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images,labels in dataset:\n",
        "      \n",
        "      # Converting 28*28 pixel image to 784 pixel vector\n",
        "      images = images.view(images.shape[0],-1)\n",
        "      \n",
        "      # Training Pass\n",
        "      output = model.forward(images)\n",
        "      loss = criterion(output,labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Zero all the previous gradients before next pass\n",
        "      optimizer.zero_grad()\n",
        "      running_loss += loss.item()\n",
        "      \n",
        "    else:\n",
        "        print(f\"Training loss : {running_loss/len(trainloader)}\")\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2p6JjcCwRtWM",
        "colab_type": "code",
        "outputId": "34d93364-8b34-4389-b03c-aab91d4191f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images,labels = next(iter(trainloader))\n",
        "img = images[0].view(1,784)\n",
        "\n",
        "model = create_train_nn(trainloader)\n",
        "#Turn off gradient to speed up this part\n",
        "with torch.no_grad():\n",
        "  logits = model.forward(img)\n",
        "  \n",
        "ps = F.softmax(logits,dim=1)\n",
        "helper.view_classify(img.view(1,28,28),ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss : 1.8918549244337752\n",
            "Training loss : 0.8288188673603509\n",
            "Training loss : 0.5181742148326912\n",
            "Training loss : 0.4304565435914851\n",
            "Training loss : 0.38638079650938384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-f319a78b9521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'view_classify'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gSD9Nft0Upgu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}